streamlit==1.25.0
# Minimum 0.40.0.post4 to fix some 4-bit precision bugs
bitsandbytes>=0.40.0.post4
# Minimum 2.16.0 to fix some bugs, see https://github.com/huggingface/datasets/pull/6444
datasets>=2.16.0
einops
# Minimum 0.1.2 to fix some bugs, see https://github.com/InternLM/lagent/pull/44
lagent>=0.1.2
# Minimum 0.10.1 to support exclude_frozen_parameters for DeepSpeedStrategy,
# see https://github.com/open-mmlab/mmengine/pull/1415, https://github.com/open-mmlab/mmengine/pull/1424
mmengine>=0.10.1
openpyxl
# Minimum 0.4.0 to support QLoRA, see https://github.com/huggingface/peft/pull/476
peft>=0.4.0
scipy
SentencePiece
tiktoken
torch
# Minimum 4.32.1 to support the QLoRA fine-tune of ChatGLM2
# Exclude 4.34.1, 4.35.0, 4.35.1, 4.35.2 to avoid BC-break,
# see https://github.com/huggingface/transformers/pull/27020, https://github.com/huggingface/transformers/pull/27073
transformers>=4.32.1,!=4.34.1,!=4.35.0,!=4.35.1,!=4.35.2
transformers_stream_generator
deepspeed>=0.12.3
mpi4py-mpich
modelscope
transformers==4.35.2
accelerate==0.24.1
langchain==0.0.292
chromadb==0.4.15
sentence-transformers==2.2.2
unstructured==0.10.30
markdown==3.3.7
huggingface_hub

